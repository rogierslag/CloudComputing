\documentclass[a4paper]{IEEEtran}

\usepackage{graphicx}
\usepackage[numbers,square,comma]{natbib}
\usepackage{hyperref}

\title{Cloud Computing: \\ Report}
\author{Steffan Norberhuis\\ 1509306 \and
 Rogier Slag\\ 1507761}

\author{
    \IEEEauthorblockN{Steffan Norberhuis, Rogier Slag}\\
    \IEEEauthorblockA{1509306, 1507761}
}

\begin{document}
\maketitle
\begin{center}
\today
\end{center}

\section{Abstract}

Over the last few years the web has become a place for multimedia.
With this change, the demand for quick and scalable video conversion has grown.
To make videos available to the largest set of consumers, it has to be transcoded to various formats and resolutions.
Meanwhile, this needs to be done at the lowest costs, but this should not mean the conversion time should suffer.\\
\\
This report introduces a prototype of an online, cloud-based, and scalable solution which optimizes for cost, while the conversion time is not significantly affected. 
Additionally, the application can easily cope with random failures of workers.
The final result is described and benchmarked to allow comparison to other systems.

\section{Introduction}


WantCloud B.V. is the European market leader in fast and cheap video conversion.
Unfortunately, their server systems are quite outdated and therefore expensive to run.
If no action is taken now, they might lose their competitive advantage.\\
\\
To remain market leader and lower waiting times when there is a high demand, the CEO of WantCloud requested an in-depth investigation of the possibilities to utilize external resources, such as an IaaS-provider (Instrastructure as a Service).
Using the \textit{cloud} for these purposes would have several advantages:

\begin{enumerate}
\item Pay for the number of machines needed at the time.
\item Flexibility of number of worker nodes (scale up and down quickly)
\item Economy of scale of the IAAS for the administrators and hardware.
\item Lower up-front costs
\item No more on-site hardware and hardware failures
\end{enumerate}

In this paper we propose a solution and present an implementation, complete with benchmarks.
As is currently the case, FFMPEG is used to handle the video conversion itself, Amazon Web Services is used as an IaaS-provider.
The software is developed in Java. For provisioning related activity, SSH is used.
\\
\\
\textit{Proposed solution}: Using the flexibility of EC2, Amazons cloud computing platform, we can continuously run one instance to monitor the number of requested jobs, the cluster status and notify customers once their jobs completed.
This instance therefore performs the roles of \textit{scheduler}, \textit{provisioner}, and \textit{health checker}.
The probability this node goes down is low, and in case it goes down it may easily be restarted on any other node.
\\
Additionally the provisioner can start extra workers, using the API made available by Amazon.
It does this based on parameters which can easily be modified, such as maximum task to worker ratio, max number of workers, or maximum waiting time.
Since the system runs many workers, the likelihood of one failing is much larger. 
Hence in case of a failure the worker should be terminated, removed from the cluster and its jobs rescheduled.
\\
\\
This paper is set up as follows.
Section 3 will deal with the background of the application.
Section 4 will explore the design of the system and any policies involved. 
Section 5 will show the experimental setup and show and interpret the benchmarks which were run.
In section 6 a discussion is done over the results.
This then leads to a conclusion in section 7.

Any source code discussed in this report and the report itself is available publicly on \href{https://github.com/snorberhuis/CloudComputing}{github}.

\section{Background on Application}

The application has as goal to convert any user submitted video to an MPEG-4 format (note this format is covered by several patents in countries which acknowledge software algorithms patents \cite{mpegla}.
For this, users can use the existing client software of WantCloud to upload their video to the servers and receive a notification of the same application once the conversion is done.
In the background, transparent to the user, the video is added to the job list by the scheduler software running on the incoming server.
This scheduler, together with the part which handles provisioning of VM's on a IaaS-provider, places the job on a server for conversion.
Due to the nature of video-conversion, a server is considered busy if there is one job running on it, and idle if no job is running on it. 
No server will handle two jobs at once.
The provisioner may decide to pin up additional VM's based on several, user-defined, criteria.
Once the conversion is done, the worker VM uploads the new file to the output server, which then performs a callback on the earlier mentioned client application.\\
\\
\textit{Requirements:} For the system to work in production, it should ensure the following requirements are met:

\begin{enumerate}
\item For the system to work well for WantCloud B.V., it should have a better performance compared to the existing platform, while at the same time it should lower monthly operational costs,
\item The system should work completely automated, requiring no intervention for any worker nodes, this goes for the autoscaling, handle worker failures, and scheduling.
\item The system should monitor its own state, both in terms of performance as well as for availability.
\item The results should remain available for users to re-download, hence durability is important.

\end{enumerate}


\section{System Design}
%Recommended Size 1.5 pages

\subsection{Resource Management Architecture}

The system is designed using a regular client-server model.
Customers can upload their videos using the application.
The application (not part of this implementation) uploads the video to an Amazon S3 bucket.
This bucket is regularly scanned by the master instance, which generates job and places them into a queue.
The master instance then assigns these jobs to machines, based on a first-come-first-serve principle.
Once a job is done, the result is saved to another Amazon S3 bucket, where the file is available for downloads.
\\
This approach has multiple advantages.
First of all, all information is durable and the data will be preserved (even in case all instances go down).
Secondly one is able to take down the master instance (e.g. for a new deployment) without affecting the customers ability to upload new videos to the system.
\\
\\
The server (the master instance) consists of several components:

\begin{enumerate}
\item
The scheduler:
this part of the application regularly checks for new files and add them to the queue.
The head of the queue is assigned to the next available worker.
\item
The Provisioner:
this section has the responsibility to monitor the number of workers nodes, spawn new ones when thresholds are met, and handles the creation and termination of worker nodes.
\item
The health checker:
which is responsible to ensure every node in the cluster is healthy, it requests checks from worker nodes at a regular interval.
Once a worker node misses a certain number of checks, it is considered to have failed and it terminates the node.
The job of the failed worker node is re-added to the queue.
\end{enumerate}

All thresholds and settings are managed by a simple configuration file (`scheduler.properties`).
The current system is based on Amazon as a provider, but this implementation can be easily changed to also support other providers such as Microsoft Azure.
\\
\\
For simplicity the system has one job list, to which each new job is added.
Each job keeps track of its status either `QUEUED`, `STARTED`, `FINISHED`, or `FAILED`.
Jobs are downloaded from and uploaded to AWS S3 using the AWS SDK, which offers a TransferManager abstraction class to handle the IO operations to the workers nodes.
Workers nodes are provisioned using the same SDK and are started by executing a simple script through SSH.
A worker will then get its source directly from Github, build the Maven project and start running.
By responding to the healthchecks, the provisioner is made aware that the start proces has been completed
and the node is added to the pool. 
The scheduler will now start assigning jobs to the node.
If a node fails to come online within five minutes, a failure is assumed and the node is terminated again.
\\
\\
The worker nodes contain as little logic as possible and this makes them to be ready for termination at any moment.
Each node is required to communicate with the master instance.
Messages are sent for each assignment (from master to worker), each status update (from worker to master) and for healthchecks (bidirectional).
Since all information is gathered at the master instance, this is also the location where statistics regarding performance are stored.
\\
\\
To improve reliability, we assume that worker node can fail at any given point in time
and have to be prepared for this.
To adequately build the system to handle this, we have introduced Chaosmonkey.
Chaosmonkey can be configured to run at a certain interval with a certain probability, in case it runs it will pick a worker node 
and on purpose let this node fail.
The Chaosmonkey communicates directly with Amazon, so neither the worker nor the master instance know what happened and should simply react to the results of the healthcheck.
However, it will log to the master instance log its activity, such that an operator can easily see this was an intended failure.
The Chaosmonkey makes failure a natural part of the system performance.
This forces us to always deal with failure and let us test reliability.
Chaosmonkey is an idea that was published and is used by Netflix in their production environment\cite{Netflix-cm}

\subsection{System Policies}

The system always uses a elastic scaling policy. There are several parameters which can be set to define the policy.

\begin{enumerate}
\item A task should not be waiting for over a certain number of seconds.
If that is the case, under-capacity is anticipated and new nodes are provisioned.
\item The ratio between tasks and nodes should not exceed a set threshold. 
If that is the case, it is assumed that there is too little capacity, so a new node is provisioned.
\item While a new node is being provisioned, no other provisioning will start.
\item A maximum number of nodes can be specified to avoid very high costs by a dDos similar attack.
\end{enumerate}

As one can see the provisioning scheme is fairly conservative.
There are several good reasons for this.
First from talks at WantCloud it was discovered an incidental delay is not problematic.
Secondly many \textit{eager} provisioning schemes in the cloud suffer from oscillation, where a set of nodes is constantly being created and terminated.
In the time between their creation and termination, they cannot complete a job (and hence are a waste of resources and money).
Hence in this case the decision was made to focus on cost-efficiency over performance.
\\
\\
Once a VM goes idle and there is no new job for it to process, it will be terminated.
Using the provisioning policy this is not an issue, since no new node will be started immediately, but the system waits for a node to become free (or at some point will start a new node).

\section{Experimental Results}
In this section the experimental setup and the experiments themselves are described.
Observations and experiments are also included in this section.

\subsection{Experimental setup}
%Describe working environments
The system was developed for Amazon AWS and was tested on that platform.
Amazon AWS provides different types of instances and for this case the \emph{t2.micro} instances were used.
These are the smallest instances provided and we could achieve higher performance on larger instances,
 but they were chosen because they are Free Tier eligible.
Video conversion itself is mostly CPU intensive, so the instances with 2.5GHz and 1 GB of memory could be outperformed by larger instances.

%Describe general workload
A specially designed workload generator creates a new task at a regular interval and offers this task to the system using the input bucket.
The task can either be a completely new task or with a certain chance be a task already offered to the system before.
The tasks consist of encoding a movie from one format to another format.

%Describe monitoring tools and libraries
To monitor the system \emph{The Simple Logging Facade for Java} (SLF4J) in combination with \emph{Log4J} were used, which allowed optimal and tunable logging.
SLF4J provides a facade for Log4J to allow other logging backends to be configured at runtime.
For this specific case simple logging output was employed to measure the performance and other statistics of the system.
%other tools

\subsection{Experiments}

%Desribe the experiments per system feature
%Format: describe workload, present operation, analyze result.
\subsubsection{Automation}
No specific experiments were ran to test the automation of the proposed system, but the other experiments have shown that a very high level of automation was been achieved.
To start only a handful of mandatory steps had to be done, after which the system runs completely without manual intervention.
The first step is to create a EC2 instance which will act as a master instance.
After that one uploads the code and runs an install script that sets up the master instance.
The last step is to build the code and run it.

\subsubsection{Elasticity}

%Provisioning time
In our first experiment we wanted to see how long it takes to provision a worker node and how long it takes before it is fully ready to service tasks.
Our experiment consists of the provisioner provisioning continuously a single worker after the previous worker becomes fully ready.
The experiment showed that the average and median time of provisioning a fully working node is 2 minutes and 31 seconds.
The minimum time of provisioning was 2 minutes and the maximum 4 minutes and 47 seconds.
A note has to be made that the timing is done with a granularity of 15 seconds, because that was the interval we checked if nodes came online.
But this experiment still gives a very good indication of the time it takes to provision a worker node.

%Elasticity
The second experiment that was conducted was to have the workload generator generate 100 jobs with a random interval between 10 and 30 seconds.
The experiment is to test that our provisioner provisions more nodes and terminates these nodes after these 100 jobs are completed.
At first the system builds a backlog of queues and the provisioner conservatively allocates more workers.
After 27 minutes all jobs are finished and it can be seen that the provisioner quickly terminates the (now) unnecessary workers.
While downscaling, a very eager approach is used.
This helps to optimize for cost.
At the end a tail can be seen where one worker is kept running.
This data is plotted in Fig. \ref{fig:100-workers} and Fig. \ref{fig:100-tasks}.

\begin{figure}[ht]
	\includegraphics[scale=0.5]{fig/100workers.png}
	\label{fig:100-workers}
	\caption{Amount of workers}
\end{figure}

\begin{figure}[ht]
	\includegraphics[scale=0.5]{fig/100tasks.png}
	\label{fig:100-tasks}
	\caption{Amount of queued tasks}
\end{figure}

\subsubsection{Performance}
Load balancing is very important to achieve a higher utilization of the VMs.
Early during the development of the proposed system CPU utilization of the used VMs was measured.
It was found that ffmpeg is very effective and used the full CPU power during execution.
As there is no more performance to be gained, scheduling more tasks on a single node could not achieve a higher utilization.
This was the main reason to let one node only work on one job at once.

\subsubsection{Reliability}

\subsubsection{Monitoring components}

%Report charged-time
%Report charged cost
%Report service metrics

\section{Discussion}

\section{Conclusion}

\bibliography{bibliography}
\bibliographystyle{unsrtnat}


\appendix
\section{Time Sheets}
\end{document}
