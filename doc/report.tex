\documentclass[a4paper]{IEEEtran}

\usepackage[numbers,square,comma]{natbib}
\usepackage{hyperref}

\title{Cloud Computing: \\ Report}
\author{Steffan Norberhuis\\ 1509306 \and
 Rogier Slag\\ 1507761}

\author{
    \IEEEauthorblockN{Steffan Norberhuis, Rogier Slag}\\
    \IEEEauthorblockA{1509306, 1507761}
}

\begin{document}
\maketitle
\begin{center}
\today
\end{center}

\section{Abstract}

Over the last few years the web has become a place for multimedia.
With this change, the demand for quick and scalable video conversion has grown.
To make videos available to the largest set of consumers, it has to be transcoded to various formats and resolutions.
Meanwhile, this needs to be done at the lowest costs, but this should not mean the conversion time should suffer.\\
\\
This report introduces a prototype of an online, cloud-based, and scalable solution which optimizes for cost, while the conversion time is not significantly affected. 
Additionally, the application can easily cope with random failures of workers.
The final result is described and benchmarked to allow comparison to other systems.

\section{Introduction}


WantCloud B.V. is the European market leader in fast and cheap video conversion.
Unfortunately, their server systems are quite outdated and therefore expensive to run.
If no action is taken now, they might lose their competitive advantage.\\
\\
To remain market leader and lower waiting times when there is a high demand, the CEO of WantCloud requested an in-depth investigation of the possibilities to utilize external resources, such as an IaaS-provider (Instrastructure as a Service).
Using the \textit{cloud} for these purposes would have several advantages:

\begin{enumerate}
\item Pay for the number of machines needed at the time.
\item Flexibility of number of worker nodes (scale up and down quickly)
\item Economy of scale of the IAAS for the administrators and hardware.
\item Lower up-front costs
\item No more on-site hardware and hardware failures
\end{enumerate}

In this paper we propose a solution and present an implementation, complete with benchmarks.
As is currently the case, FFMPEG is used to handle the video conversion itself, Amazon Web Services is used as an IaaS-provider.
The software is developed in Java. For provisioning related activity, SSH is used.
\\
\\
\textit{Proposed solution}: Using the flexibility of EC2, Amazons cloud computing platform, we can continuously run one instance to monitor the number of requested jobs, the cluster status and notify customers once their jobs completed.
This instance therefore performs the roles of \textit{scheduler}, \textit{provisioner}, and \textit{health checker}.
The probability this node goes down is low, and in case it goes down it may easily be restarted on any other node.
\\
Additionally the provisioner can start extra workers, using the API made available by Amazon.
It does this based on parameters which can easily be modified, such as maximum task to worker ratio, max number of workers, or maximum waiting time.
Since the system runs many workers, the likelihood of one failing is much larger. 
Hence in case of a failure the worker should be terminated, removed from the cluster and its jobs rescheduled.
\\
\\
This paper is set up as follows.
Section 3 will deal with the background of the application.
Section 4 will explore the design of the system and any policies involved. 
Section 5 will show the experimental setup and show and interpret the benchmarks which were run.
In section 6 a discussion is done over the results.
This then leads to a conclusion in section 7.

Any source code discussed in this report and the report itself is available publicly on \href{https://github.com/snorberhuis/CloudComputing}{github}.

\section{Background on Application}

The application has as goal to convert any user submitted video to an MPEG-4 format (note this format is covered by several patents in countries which acknowledge software algorithms patents \cite{mpegla}.
For this, users can use the existing client software of WantCloud to upload their video to the servers and receive a notification of the same application once the conversion is done.
In the background, transparent to the user, the video is added to the job list by the scheduler software running on the incoming server.
This scheduler, together with the part which handles provisioning of VM's on a IaaS-provider, places the job on a server for conversion.
Due to the nature of video-conversion, a server is considered busy if there is one job running on it, and idle if no job is running on it. 
No server will handle two jobs at once.
The provisioner may decide to pin up additional VM's based on several, user-defined, criteria.
Once the conversion is done, the worker VM uploads the new file to the output server, which then performs a callback on the earlier mentioned client application.\\
\\
\textit{Requirements:} For the system to work in production, it should ensure the following requirements are met:

\begin{enumerate}
\item For the system to work well for WantCloud B.V., it should have a better performance compared to the existing platform, while at the same time it should lower monthly operational costs,
\item The system should work completely automated, requiring no intervention for any worker nodes, this goes for the autoscaling, handle worker failures, and scheduling.
\item The system should monitor its own state, both in terms of performance as well as for availability.
\item The results should remain available for users to re-download, hence durability is important.

\end{enumerate}


\section{System Design}
%Recommended Size 1.5 pages

\subsection{Resource Management Architecture}

The system is designed using a regular client-server model.
Customers can upload their videos using the application.
The application (not part of this implementation) uploads the video to an Amazon S3 bucket.
This bucket is regularly scanned by the master instance, which generates job and places them into a queue.
The master instance then assigns these jobs to machines, based on a first-come-first-serve principle.
Once a job is done, the result is saved to another Amazon S3 bucket, where the file is available for downloads.
\\
This approach has multiple advantages.
First of all, all information is durable and the data will be preserved (even in case all instances go down).
Secondly one is able to take down the master instance (e.g. for a new deployment) without affecting the customers ability to upload new videos to the system.
\\
\\
The server (the master instance) consists of several components:

\begin{enumerate}
\item
The scheduler:
this part of the application regularly checks for new files and add them to the queue.
The head of the queue is assigned to the next available worker.
\item
The Provisioner:
this section has the responsibility to monitor the number of workers nodes, spawn new ones when thresholds are met, and handles the creation and termination of worker nodes.
\item
The health checker:
which is responsible to ensure every node in the cluster is healthy, it requests checks from worker nodes at a regular interval.
Once a worker node misses a certain number of checks, it is considered to have failed and it terminates the node.
The job of the failed worker node is re-added to the queue.
\end{enumerate}

All thresholds and settings are managed by a simple configuration file (`scheduler.properties`).
The current system is based on Amazon as a provider, but this implementation can be easily changed to also support other providers such as Microsoft Azure.
\\
\\
For simplicity the system has one job list, to which each new job is added.
Each job keeps track of its status either `QUEUED`, `STARTED`, `FINISHED`, or `FAILED`.
Jobs are downloaded from and uploaded to AWS S3 using the AWS SDK, which offers a TransferManager abstraction class to handle the IO operations to the workers nodes.
Workers nodes are provisioned using the same SDK and are started by executing a simple script through SSH.
A worker will then get its source directly from Github, build the Maven project and start running.
By responding to the healthchecks, the provisioner is made aware that the start proces has been completed
and the node is added to the pool. 
The scheduler will now start assigning jobs to the node.
If a node fails to come online within five minutes, a failure is assumed and the node is terminated again.
\\
\\
The worker nodes contain as little logic as possible and this makes them to be ready for termination at any moment.
Each node is required to communicate with the master instance.
Messages are sent for each assignment (from master to worker), each status update (from worker to master) and for healthchecks (bidirectional).
Since all information is gathered at the master instance, this is also the location where statistics regarding performance are stored.
\\
\\
To improve reliability, we assume that worker node can fail at any given point in time
and have to be prepared for this.
To adequately build the system to handle this, we have introduced Chaosmonkey.
Chaosmonkey can be configured to run at a certain interval with a certain probability, in case it runs it will pick a worker node 
and on purpose let this node fail.
The Chaosmonkey communicates directly with Amazon, so neither the worker nor the master instance know what happened and should simply react to the results of the healthcheck.
However, it will log to the master instance log its activity, such that an operator can easily see this was an intended failure.
The Chaosmonkey makes failure a natural part of the system performance.
This forces us to always deal with failure and let us test reliability.
Chaosmonkey is an idea that was published and is used by Netflix in their production environment\cite{Netflix-cm}

\subsection{System Policies}

The system always uses a elastic scaling policy. There are several parameters which can be set to define the policy.

\begin{enumerate}
\item A task should not be waiting for over a certain number of seconds.
If that is the case, under-capacity is anticipated and new nodes are provisioned.
\item The ratio between tasks and nodes should not exceed a set threshold. 
If that is the case, it is assumed that there is too little capacity, so a new node is provisioned.
\item While a new node is being provisioned, no other provisioning will start.
\item A maximum number of nodes can be specified to avoid very high costs by a dDos similar attack.
\end{enumerate}

As one can see the provisioning scheme is fairly conservative.
There are several good reasons for this.
First from talks at WantCloud it was discovered an incidental delay is not problematic.
Secondly many \textit{eager} provisioning schemes in the cloud suffer from oscillation, where a set of nodes is constantly being created and terminated.
In the time between their creation and termination, they cannot complete a job (and hence are a waste of resources and money).
Hence in this case the decision was made to focus on cost-efficiency over performance.
\\
\\
Once a VM goes idle and there is no new job for it to process, it will be terminated.
Using the provisioning policy this is not an issue, since no new node will be started immediately, but the system waits for a node to become free (or at some point will start a new node).

\section{Experimental Results}
%Recommended size 1.5 pages

\subsection{Experimental setup}
%Describe working environments

%Describe general workload

%Describe monitoring tools and libraries

%other tools

\subsection{Experiments}
%Desribe the experiments per system feature
%Format: describe workload, present operation, analyze result.
\subsubsection{Provisioning}

\subsubsection{Allocation}

\subsubsection{Reliability}

\subsubsection{Monitoring components}

%Report charged-time
%Report charged cost
%Report service metrics

\section{Discussion}

\section{Conclusion}

In this report, a elastic cloud based system was proposed to handle different kinds of video conversion.
Consequently, the performance and costs were analyzed for a representative test set using Amazon Web Services as an IaaS-provider.
\\
\\
From the results in the experimental section we can see that the provisioning is done conservatively, whereas the termination of nodes is done eagerly.
This provides a nice optimization for costs.
\\
\\
On the other hand, once a node has been provisioned it will continue to perform jobs until there is no more work for it. 
This will allow the system to fully utilize the node in order to minimize the non-production time (the time once one started paying for the computing power until the moment the node could start its first job).
This timespan is mostly dependent on the cloud provider and the method of provisioning.
Using very simple software on the nodes, the installation of the node can be done in around one minute.
Another minute is needed to actually \textit{lease} the machine from the provider, in this case Amazon.
\\
\\


\bibliography{bibliography}
\bibliographystyle{unsrtnat}


\appendix
\section{Time Sheets}
\end{document}
